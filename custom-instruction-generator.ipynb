{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Instruction Generator\n",
    "\n",
    "This notebook leverages [LangChain's prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/) to generate custom instructions for GPT-3 to follow. The instructions are generated based on the user's input and the output is a string of instructions that can be used by GPT to generate a more tailored response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_template = \"\"\"You are a {profession} at {workplace}. You are currently {activity}. Your goal is to {goal}.\n",
    "\n",
    "A language model is available to you. You can use it to improve your workflow, and achieve your goal. To produce better responses, you must provide the language model with relevant information about yourself. Therefore, please write a statement that introduces yourself. Consider these criteria in writing your statement:\n",
    "\n",
    "- Limit the response to 200 words.\n",
    "- Use first person point-of-view.\n",
    "- Write in academic English. Be formal.\n",
    "- Do not use figurative language. Be on-point.\n",
    "\n",
    "Use these details about yourself in your statement:\n",
    "\n",
    "{details}\n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", user_template),\n",
    "])\n",
    "\n",
    "details = [\n",
    "    \"Interested in natural language processing and machine learning.\",\n",
    "    \"Can use Python and C++ for your work.\",\n",
    "    \"Knowledgeable about semantic embedding and cosine similarity.\",\n",
    "    \"Planning to use vector databases for the knowledge base.\",\n",
    "    \"Experiences difficulty in learning new concepts.\",\n",
    "    \"Has a hard time understanding the math behind machine learning.\",\n",
    "    \"Good at writing technical documentation.\",\n",
    "]\n",
    "\n",
    "messages = template.format_messages(\n",
    "    profession=\"software engineer\",\n",
    "    workplace=\"Google\",\n",
    "    activity=\"working on a new project about machine learning\",\n",
    "    goal=\"produce an knowledge base assistant\",\n",
    "    details=\"\\n\".join([\"- \" + d for d in details]),\n",
    ")\n",
    "\n",
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send prompt to OpenAI API\n",
    "\n",
    "When instantiating `ChatOpenAI`, it automatically reads the value of the environment variable `OPENAI_API_KEY` and uses it to authenticate with the OpenAI API. If you have not set this variable, you can pass the key directly to the constructor using the `openai_api_key` parameter. The `ChatOpenAI` class also sets \"gpt-3.5-turbo\" as the default language model. To pass a different model, use the `model` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Raw response containing all message chunks:\\n\\n{response}\\n\")\n",
    "print(f\"Character count: {len(response.content)}\")\n",
    "print(f\"Word count: {len(response.content.split())}\")\n",
    "print(f\"Token count: {chat.get_num_tokens(response.content)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
